import requests
import json
import time
from datetime import datetime

# CONFIGURACIÓN
SERIES_ID = "1CjTiHEJbLRC" # Miraculous

# Lista de Regiones (Prioridad + Global)
REGIONS = [
    # América
    {"c":"AR", "l":"es-419"}, {"c":"MX", "l":"es-419"}, {"c":"BR", "l":"pt-BR"},
    {"c":"US", "l":"en-US"}, {"c":"CA", "l":"en-CA"}, {"c":"CL", "l":"es-419"},
    {"c":"CO", "l":"es-419"}, {"c":"PE", "l":"es-419"}, {"c":"UY", "l":"es-419"},
    {"c":"FK", "l":"es-419"}, {"c":"PR", "l":"es-419"},
    # Europa
    {"c":"ES", "l":"es-ES"}, {"c":"FR", "l":"fr-FR"}, {"c":"DE", "l":"de-DE"},
    {"c":"IT", "l":"it-IT"}, {"c":"GB", "l":"en-GB"}, {"c":"PT", "l":"pt-PT"},
    {"c":"NL", "l":"nl-NL"}, {"c":"SE", "l":"sv-SE"}, {"c":"NO", "l":"no-NO"},
    {"c":"DK", "l":"da-DK"}, {"c":"FI", "l":"fi-FL"}, {"c":"PL", "l":"pl-PL"},
    {"c":"RO", "l":"ro-RO"}, {"c":"TR", "l":"tr-TR"},
    # Asia/Oceanía
    {"c":"JP", "l":"ja-JP"}, {"c":"KR", "l":"ko-KR"}, {"c":"SG", "l":"en-SG"},
    {"c":"AU", "l":"en-AU"}, {"c":"NZ", "l":"en-NZ"}, {"c":"TW", "l":"zh-Hant-TW"},
    {"c":"HK", "l":"zh-Hant-HK"}
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'application/json'
}

def get_data():
    database = {
        "meta": { "updated": datetime.utcnow().strftime("%d/%m/%Y %H:%M UTC") },
        "regions": {}
    }

    print(f"--- ESCANEANDO {len(REGIONS)} REGIONES (Full Data) ---")

    for idx, reg in enumerate(REGIONS):
        code = reg['c']
        lang = reg['l']
        
        try:
            # 1. Bundle (Temporadas)
            url_bundle = f"https://disney.content.edge.bamgrid.com/svc/content/DmcSeriesBundle/version/5.1/region/{code}/audience/k-false,l-true/maturity/1899/language/{lang}/encodedSeriesId/{SERIES_ID}"
            r = requests.get(url_bundle, headers=HEADERS, timeout=5)

            if r.status_code == 200:
                data = r.json()
                seasons = data.get('data', {}).get('DmcSeriesBundle', {}).get('seasons', {}).get('seasons', [])
                
                region_data = {"seasons": [], "news": []}
                print(f"[{idx+1}/{len(REGIONS)}] {code}: OK ({len(seasons)} temps)")

                for s in seasons:
                    s_id = s['seasonId']
                    s_num = s.get('seasonSequenceNumber', 0)
                    
                    # 2. Episodios
                    url_eps = f"https://disney.content.edge.bamgrid.com/svc/content/DmcEpisodes/version/5.1/region/{code}/audience/k-false,l-true/maturity/1899/language/{lang}/seasonId/{s_id}/pageSize/60/page/1"
                    r_eps = requests.get(url_eps, headers=HEADERS, timeout=5)
                    
                    if r_eps.status_code == 200:
                        eps_raw = r_eps.json().get('data', {}).get('DmcEpisodes', {}).get('videos', [])
                        clean_eps = []
                        
                        for ep in eps_raw:
                            date_str = ep.get('availabilityDate', '')
                            # Detectar Novedad (90 días)
                            is_new = False
                            if date_str:
                                try:
                                    dt = datetime.strptime(date_str.split('T')[0], "%Y-%m-%d")
                                    if 0 <= (datetime.utcnow() - dt).days <= 90: is_new = True
                                except: pass

                            # Extraer datos COMPLETOS
                            title = ep.get('text', {}).get('title', {}).get('full', {}).get('program', {}).get('default', {}).get('content', 'Sin Título')
                            
                            # Intentar obtener descripción media, sino breve
                            desc = ep.get('text', {}).get('description', {}).get('medium', {}).get('program', {}).get('default', {}).get('content')
                            if not desc:
                                desc = ep.get('text', {}).get('description', {}).get('brief', {}).get('program', {}).get('default', {}).get('content', '')

                            ep_obj = {
                                "n": ep.get('sequenceNumber', 0),
                                "t": title,
                                "ds": desc, # Descripción
                                "dt": date_str.split('T')[0] if date_str else "", # Fecha
                                "a": [x.get('renditionName', x.get('language')) for x in ep.get('mediaMetadata', {}).get('audioTracks', [])], # Todos los audios
                                "s": [x.get('renditionName', x.get('language')) for x in ep.get('mediaMetadata', {}).get('captionTracks', [])]  # Todos los subs
                            }
                            
                            clean_eps.append(ep_obj)
                            if is_new: 
                                region_data["news"].append({"e":f"T{s_num} E{ep_obj['n']}", "t":title, "d":ep_obj['dt']})

                        region_data["seasons"].append({"id": s_num, "eps": clean_eps})

                if region_data["seasons"]:
                    database["regions"][code] = region_data
            else:
                print(f"[{idx+1}] {code}: Sin datos ({r.status_code})")

        except Exception as e:
            print(f"[{idx+1}] {code}: Error conexión.")

        time.sleep(0.3)

    return database

if __name__ == "__main__":
    try:
        data = get_data()
        with open("database.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False)
        print("Done.")
    except Exception as e:
        print(f"Fatal Error: {e}")
