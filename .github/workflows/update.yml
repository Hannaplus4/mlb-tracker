import requests
import json
import time
from datetime import datetime

# --- CONFIGURACIÓN ---
SERIES_ID = "1CjTiHEJbLRC" # Miraculous

# LISTA REDUCIDA Y SEGURA (Solo mercados principales para probar)
# Si esto funciona rápido, puedes agregar más países luego.
REGIONS = [
    {"c":"AR", "l":"es-419"}, {"c":"MX", "l":"es-419"}, {"c":"BR", "l":"pt-BR"},
    {"c":"US", "l":"en-US"}, {"c":"ES", "l":"es-ES"}, {"c":"FR", "l":"fr-FR"},
    {"c":"GB", "l":"en-GB"}, {"c":"DE", "l":"de-DE"}, {"c":"IT", "l":"it-IT"},
    {"c":"JP", "l":"ja-JP"}, {"c":"KR", "l":"ko-KR"}, {"c":"TR", "l":"tr-TR"}
]

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Accept': 'application/json'
}

def get_data():
    database = {
        "meta": { 
            "updated": datetime.utcnow().strftime("%d/%m/%Y %H:%M UTC"),
            "status": "success"
        },
        "regions": {}
    }

    print(f"--- INICIANDO ESCANEO RAPIDO ({len(REGIONS)} PAISES) ---")

    for idx, reg in enumerate(REGIONS):
        code = reg['c']
        lang = reg['l']
        
        try:
            print(f"[{idx+1}/{len(REGIONS)}] Consultando {code}...", end="", flush=True)
            
            # 1. Bundle (Timeout estricto de 4 segundos)
            url_bundle = f"https://disney.content.edge.bamgrid.com/svc/content/DmcSeriesBundle/version/5.1/region/{code}/audience/k-false,l-true/maturity/1899/language/{lang}/encodedSeriesId/{SERIES_ID}"
            r = requests.get(url_bundle, headers=HEADERS, timeout=4)

            if r.status_code == 200:
                data = r.json()
                seasons = data.get('data', {}).get('DmcSeriesBundle', {}).get('seasons', {}).get('seasons', [])
                
                region_data = {"seasons": [], "news": []}
                print(f" OK ({len(seasons)} temps)")

                for s in seasons:
                    s_id = s['seasonId']
                    s_num = s.get('seasonSequenceNumber', 0)
                    
                    # 2. Episodios
                    url_eps = f"https://disney.content.edge.bamgrid.com/svc/content/DmcEpisodes/version/5.1/region/{code}/audience/k-false,l-true/maturity/1899/language/{lang}/seasonId/{s_id}/pageSize/60/page/1"
                    r_eps = requests.get(url_eps, headers=HEADERS, timeout=4)
                    
                    if r_eps.status_code == 200:
                        eps_raw = r_eps.json().get('data', {}).get('DmcEpisodes', {}).get('videos', [])
                        clean_eps = []
                        
                        for ep in eps_raw:
                            date_str = ep.get('availabilityDate', '')
                            is_new = False
                            if date_str:
                                try:
                                    dt = datetime.strptime(date_str.split('T')[0], "%Y-%m-%d")
                                    if 0 <= (datetime.utcnow() - dt).days <= 90: is_new = True
                                except: pass

                            title = ep.get('text', {}).get('title', {}).get('full', {}).get('program', {}).get('default', {}).get('content', 'Sin Título')
                            # Descripción simplificada para que el archivo no pese tanto
                            desc = ep.get('text', {}).get('description', {}).get('medium', {}).get('program', {}).get('default', {}).get('content', '')
                            if not desc: desc = "..."

                            ep_obj = {
                                "n": ep.get('sequenceNumber', 0),
                                "t": title,
                                "ds": desc[:150] + "..." if len(desc)>150 else desc, # Recortar descripciones largas
                                "dt": date_str.split('T')[0] if date_str else "",
                                "a": [x.get('renditionName', x.get('language')) for x in ep.get('mediaMetadata', {}).get('audioTracks', [])][:3],
                                "s": [x.get('renditionName', x.get('language')) for x in ep.get('mediaMetadata', {}).get('captionTracks', [])][:3]
                            }
                            clean_eps.append(ep_obj)
                            if is_new: region_data["news"].append({"e":f"T{s_num} E{ep_obj['n']}", "t":title, "d":ep_obj['dt']})

                        region_data["seasons"].append({"id": s_num, "eps": clean_eps})

                if region_data["seasons"]:
                    database["regions"][code] = region_data
            else:
                print(f" ERROR API ({r.status_code})")

        except Exception as e:
            print(f" TIMEOUT/ERROR.") # No detenerse, seguir al siguiente
        
        # Pausa pequeña
        time.sleep(0.5)

    return database

if __name__ == "__main__":
    # Bloque Try-Except global para asegurar que SIEMPRE se guarde un archivo JSON válido
    try:
        data = get_data()
        with open("database.json", "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False)
        print("EXITO: database.json generado.")
    except Exception as e:
        print(f"ERROR FATAL: {e}")
        # Guardar un JSON de error para que la web no se rompa
        with open("database.json", "w", encoding="utf-8") as f:
            json.dump({"meta":{"updated":"Error"}, "regions":{}}, f)
